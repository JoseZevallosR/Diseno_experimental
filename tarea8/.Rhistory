install.packages("hyetosminute")
install.packages("C:/Users/Usuario/Downloads/HyetosMinute_2.1.zip", repos = NULL, type = "win.binary")
install.packages("rtools")
install.packages("C:/Users/Usuario/Downloads/HyetosMinute_2.1.zip", repos = NULL, type = "win.binary")
library(HyetosMinute)
install.packages("gplots")
library(HyetosMinute)
install.packages("gdata")
library(HyetosMinute)
library(HyetosMinute)
install.packages("C:/Users/Usuario/Downloads/HyetosMinute_2.1.zip", repos = NULL, type = "win.binary")
library(HyetosMinute)
install.packages("C:/Usuarios/Usuario/Descargas/HyetosMinute", repos = NULL, type = "source")
library(dplyr)
library(dplyr)
library(dplyr)
library(ggplot2)
library(car)
# Cargar los datos (asegúrate de tener tu archivo .csv o .xlsx correctamente formateado)
data <- read.csv("Wellmind_ms_data.csv") # Reemplaza con la ruta de tu archivo si es necesario
# Cargar los datos (asegúrate de tener tu archivo .csv o .xlsx correctamente formateado)
data <- read.csv("Doctorado/2024-II/diseño/wellmind.csv") # Reemplaza con la ruta de tu archivo si es necesario
View(data)
# Cargar los datos (asegúrate de tener tu archivo .csv o .xlsx correctamente formateado)
data <- read.csv("Doctorado/2024-II/diseño/wellmind.csv",sep=';') # Reemplaza con la ruta de tu archivo si es necesario
View(data)
# Cargar los datos (asegúrate de tener tu archivo .csv o .xlsx correctamente formateado)
data <- read.csv("Doctorado/2024-II/diseño/wellmind.csv" , sep =';') # Reemplaza con la ruta de tu archivo si es necesario
View(data)
# Visualizar los primeros registros para verificar la estructura
head(data)
# Convertir las columnas relevantes a factores
data$Group <- as.factor(data$Group) # Grupo de intervención o control
data$Gender <- as.factor(data$Gender)
# Realizar el ANOVA para comparar las puntuaciones de "self-compassion" antes y después del entrenamiento
anova_selfcompassion <- aov(FollowUp.selfcompassion ~ Group + Error(Subject/Group), data = data)
# Realizar el ANOVA para comparar las puntuaciones de "self-compassion" antes y después del entrenamiento
anova_selfcompassion <- aov(FollowUp.selfcompassion ~ Group), data = data)
# Realizar el ANOVA para comparar las puntuaciones de "self-compassion" antes y después del entrenamiento
anova_selfcompassion <- aov(FollowUp.selfcompassion ~ Group , data = data)
View(anova_selfcompassion)
summary(anova_selfcompassion)
# Realizar el ANOVA para comparar las puntuaciones de "mindfulness" antes y después del entrenamiento
anova_mindfulness <- aov(FollowUp.trait.mindfulnessscore ~ Group, data = data)
summary(anova_mindfulness)
# Visualización gráfica de los resultados
ggplot(data, aes(x = Group, y = FollowUp.selfcompassion, fill = Group)) +
geom_boxplot() +
labs(title = "Comparación de 'Self-Compassion' entre Grupos", x = "Grupo", y = "Puntuación de Self-Compassion") +
theme_minimal()
ggplot(data, aes(x = Group, y = FollowUp.trait.mindfulnessscore, fill = Group)) +
geom_boxplot() +
labs(title = "Comparación de 'Mindfulness' entre Grupos", x = "Grupo", y = "Puntuación de Mindfulness") +
theme_minimal()
# Realizar el ANOVA para comparar las puntuaciones de "self-compassion" antes y después del entrenamiento
anova_selfcompassion <- aov(FollowUp.selfcompassion ~ Group , data = data)
summary(anova_selfcompassion)
# Realizar el ANOVA para comparar las puntuaciones de "mindfulness" antes y después del entrenamiento
anova_mindfulness <- aov(FollowUp.trait.mindfulnessscore ~ Group, data = data)
summary(anova_mindfulness)
# Load necessary library
library(dplyr)
# Original data extracted from the image
data <- data.frame(
Variable = c("Nmin_N0", "Nmin_N20", "Nmin_N40", "Nmin_N60", "Nmin_N80",
"NO3_N0", "NO3_N20", "NO3_N40", "NO3_N60", "NO3_N80",
"NH4_N_N0", "NH4_N_N20", "NH4_N_N40", "NH4_N_N60", "NH4_N_N80",
"WFPS_N0", "WFPS_N20", "WFPS_N40", "WFPS_N60", "WFPS_N80"),
Mean = c(30.4, 29.0, 26.7, 26.9, 32.8,
4.8, 5.5, 4.4, 4.4, 6.5,
25.6, 23.5, 21.3, 22.5, 26.3,
59.9, 56.3, 56.6, 58.8, 56.5),
StdDev = c(1.8, 2.3, 1.2, 1.9, 4.3,
1.3, 0.5, 0.4, 1.1, 1.1,
0.9, 1.9, 1.2, 1.2, 3.4,
1.6, 1.3, 1.9, 1.0, 2.6)
)
# Create new columns for mean - std, mean, and mean + std
data <- data %>%
mutate(Mean_minus_SD = Mean - StdDev,
Mean_plus_SD = Mean + StdDev)
# Select and reorder the columns for clarity
result_df <- data %>%
select(Variable, Mean_minus_SD, Mean, Mean_plus_SD)
# Display the resulting data frame
print(result_df)
# Crear el dataframe
data <- data.frame(
Fecha = rep("2018-05-29", times = 5 * 4),
Tratamiento = rep(c("N0", "N20", "N40", "N60", "N80"), each = 4),
Variable = rep(c("Nmin", "NO3-N", "NH4+-N", "WFPS"), times = 5),
Valor = c(30.4, 4.8, 25.6, 59.9,  # Valores para N0
29.0, 5.5, 23.5, 56.3,  # Valores para N20
26.7, 4.4, 21.3, 56.6,  # Valores para N40
26.9, 4.4, 22.5, 58.8,  # Valores para N60
32.8, 6.5, 26.3, 56.5)  # Valores para N80
)
# Mostrar el dataframe
print(data)
# Crear el dataframe original con los valores medios y la desviación estándar
data <- data.frame(
Tratamiento = c("N0", "N20", "N40", "N60", "N80"),
Nmin_mean = c(30.4, 29.0, 26.7, 26.9, 32.8),
Nmin_sd = c(1.8, 2.3, 1.2, 1.9, 4.3),
NO3_mean = c(4.8, 5.5, 4.4, 4.4, 6.5),
NO3_sd = c(1.3, 0.5, 0.4, 1.1, 1.1),
NH4_mean = c(25.6, 23.5, 21.3, 22.5, 26.3),
NH4_sd = c(0.9, 1.9, 1.2, 1.2, 3.4),
WFPS_mean = c(59.9, 56.3, 56.6, 58.8, 56.5),
WFPS_sd = c(1.6, 1.3, 1.9, 1.0, 2.6)
)
# Crear un dataframe vacío para almacenar los resultados
data_expanded <- data.frame()
# Iterar sobre cada fila del dataframe original y crear las repeticiones
for (i in 1:nrow(data)) {
# Para cada variable (Nmin, NO3-N, NH4+-N, WFPS), generar las tres repeticiones
temp <- data.frame(
Fecha = rep("2018-05-29", 12),
Tratamiento = rep(data$Tratamiento[i], 12),
Variable = rep(c("Nmin", "NO3-N", "NH4+-N", "WFPS"), each = 3),
Valor = c(
data$Nmin_mean[i] - data$Nmin_sd[i], data$Nmin_mean[i], data$Nmin_mean[i] + data$Nmin_sd[i],
data$NO3_mean[i] - data$NO3_sd[i], data$NO3_mean[i], data$NO3_mean[i] + data$NO3_sd[i],
data$NH4_mean[i] - data$NH4_sd[i], data$NH4_mean[i], data$NH4_mean[i] + data$NH4_sd[i],
data$WFPS_mean[i] - data$WFPS_sd[i], data$WFPS_mean[i], data$WFPS_mean[i] + data$WFPS_sd[i]
)
)
# Añadir los datos temporales al dataframe expandido
data_expanded <- rbind(data_expanded, temp)
}
# Mostrar el dataframe resultante
print(data_expanded)
# Asegurarse de que los factores estén correctamente definidos
data_expanded$Tratamiento <- as.factor(data_expanded$Tratamiento)
data_expanded$Variable <- as.factor(data_expanded$Variable)
# Filtrar los datos para una variable específica, por ejemplo, "Nmin"
data_Nmin <- data_expanded %>% filter(Variable == "Nmin")
# Realizar el ANOVA para la variable "Nmin"
anova_Nmin <- aov(Valor ~ Tratamiento, data = data_Nmin)
summary(anova_Nmin)
datos = read.csv("Doctorado/2024-II/FACTORIAL.csv",sep = ';')
datos
View(data_expanded)
# Asegurarse de que los factores estén correctamente definidos
data_expanded$Tratamiento <- as.factor(data_expanded$Tratamiento)
data_expanded$Variable <- as.factor(data_expanded$Variable)
res.aov <- aov(Valor ~ Tratamiento+Variable  , data = data_expanded)
summary(res.aov)
TukeyMetodo <- HSD.test(res.aov)
TukeyMetodo <- TukeyHSD(res.aov)
TukeyMetodo
datos = read.csv("Doctorado/2024-II/FACTORIAL.csv",sep = ';')
colnames(datos)
datos$Profundidad = as.factor(datos$Profundidad)
datos$Velocidad = as.factor(datos$Velocidad)
res.aov <- aov(Acabado ~ Velocidad+Profundidad + Profundidad *Velocidad  , data = datos)
summary(anova_selfcompassion)
summary(res.aov)
residuos = anova_selfcompassion$residuals
shapiro.test(x = residuos)
plot(res.aov)
plot(tukeyMetodo1,variation="IQR")
tukeyMetodo1 = HSD.test(res.aov,"Profundida", alpha =0.05, group=T)
library(lmtest)
dwtest(res.aov)
library(agricolae)
tukeyMetodo1 = HSD.test(res.aov,"Profundida", alpha =0.05, group=T)
plot(tukeyMetodo1,variation="IQR")
plot(tukeyMetodo1,variation="IQR")
TukeyMetodo <- TukeyHSD(res.aov)
res.aov <- aov(Valor ~ Tratamiento+Variable  , data = data_expanded)
summary(res.aov)
TukeyMetodo <- TukeyHSD(res.aov)
TukeyMetodo
plot(tukeyMetodo1,variation="IQR")
TukeyMetodo
plot(tukeyMetodo1,variation="IQR")
plot(tukeyMetodo1,variation="IQR")
plot(tukeyMetodo,variation="IQR")
plot(TukeyMetodo,variation="IQR")
tukeyMetodo1 = HSD.test(res.aov,"Tratamiento", alpha =0.05, group=T)
plot(tukeyMetodo1,variation="IQR")
tukeyMetodo1 = HSD.test(res.aov,"Variable", alpha =0.05, group=T)
tukeyMetodo2 = HSD.test(res.aov,"Variable", alpha =0.05, group=T)
plot(tukeyMetodo2,variation="IQR")
tukeyMetodo1 = HSD.test(res.aov,"Tratamiento", alpha =0.05, group=T)
plot(tukeyMetodo1,variation="IQR")
View(data)
View(data_expanded)
library(ggplot2)
intEf <- aggregate(Valor ~ Tratamiento + Variable,
FUN = mean, data = data_expanded)
effects_interaction <- ggplot(intEf, aes(x = Tratamiento, y = Valor, color = Variable)) +
geom_point() +
geom_line(aes(group = Variable))
effects_interaction
# Calcular los valores promedio por tratamiento y variable
intEf <- aggregate(Valor ~ Tratamiento + Variable, FUN = mean, data = data_expanded)
# Crear el gráfico con las unidades añadidas
effects_interaction <- ggplot(intEf, aes(x = Tratamiento, y = Valor, color = Variable)) +
geom_point() +
geom_line(aes(group = Variable)) +
labs(
y = "Valor (kg N ha⁻¹ para Nmin, NH4+-N, NO3-N; % para WFPS)",
x = "Tratamiento",
color = "Variable (Unidad)"
) +
scale_color_manual(
values = c("NH4+-N" = "red", "Nmin" = "green", "NO3-N" = "blue", "WFPS" = "purple"),
labels = c(
"NH4+-N (kg N ha⁻¹)",
"Nmin (kg N ha⁻¹)",
"NO3-N (kg N ha⁻¹)",
"WFPS (%)"
)
)
# Mostrar el gráfico
effects_interaction
# Cargar librerías necesarias
library(dplyr)
library(agricolae)
library(car) # Para la verificación de suposiciones
# Crear el dataframe original con los valores medios y la desviación estándar para cada variable
data <- data.frame(
Intensidad_Pastoreo = c("G0", "G0.7", "G1.2", "G1.6"),
P_mean = c(0.86, 1.74, 1.14, 1.42),
P_sd = c(0.04, 0.08, 0.04, 0.12),
NO3_mean = c(0.07, 0.12, 0.10, 0.08),
NO3_sd = c(0.004, 0.006, 0.008, 0.01),
NH4_mean = c(1.26, 1.13, 1.22, 1.37),
NH4_sd = c(0.08, 0.06, 0.06, 0.11)
)
# Crear un dataframe vacío para almacenar los resultados
data_expanded <- data.frame()
# Iterar sobre cada fila del dataframe original y crear las repeticiones
for (i in 1:nrow(data)) {
# Para cada variable (P, NO3-N, NH4+-N), generar las tres repeticiones
temp <- data.frame(
Fecha = rep("2013", 9),  # Ajuste de fecha para el año del estudio
Intensidad_Pastoreo = rep(data$Intensidad_Pastoreo[i], 9),
Psuelo = rep(c("P", "NO3-N", "NH4+-N"), each = 3),
Valor = c(
data$P_mean[i] - data$P_sd[i], data$P_mean[i], data$P_mean[i] + data$P_sd[i],
data$NO3_mean[i] - data$NO3_sd[i], data$NO3_mean[i], data$NO3_mean[i] + data$NO3_sd[i],
data$NH4_mean[i] - data$NH4_sd[i], data$NH4_mean[i], data$NH4_mean[i] + data$NH4_sd[i]
)
)
# Añadir los datos temporales al dataframe expandido
data_expanded <- rbind(data_expanded, temp)
}
# Mostrar el dataframe expandido
print(data_expanded)
View(data)
View(data_expanded)
data_expanded$Fecha = NULL
# Ordenar el dataframe expandido por la columna "Variable"
data_expanded <- arrange(data_expanded, Psuelo)
# Reorganizar las columnas para que "Variable" sea la primera
data_expanded <- select(data_expanded, Psuelo, everything())
View(data_expanded)
View(data_expanded)
# Mostrar el dataframe resultante
print(data_expanded)
# Asegurarse de que los factores estén correctamente definidos
data_expanded$Intensidad_Pastoreo <- as.factor(data_expanded$Intensidad_Pastoreo)
data_expanded$Psuelo <- as.factor(data_expanded$Psuelo)
# Anova para DBCA
res.aov <- aov(Valor ~ Intensidad_Pastoreo + Psuelo, data = data_expanded)
summary(res.aov)
shapiro.test(aov_residuals)
# Si hay normalidad en nuestros datos
aov_residuals = residuals(res.aov)
shapiro.test(aov_residuals)
bartlett.test(Valor ~ Intensidad_Pastoreo, data = data_expanded)
bartlett.test(Valor ~ Psuelo, data = data_expanded)
# Durbin-Watson test
lmtest::dwtest(res.aov)
# Cargar librerías necesarias
library(dplyr)
library(agricolae)
library(car) # Para la verificación de suposiciones
# Crear el dataframe original con los valores medios y la desviación estándar para cada variable
data <- data.frame(
Intensidad_Pastoreo = c("G0", "G0.7", "G1.2", "G1.6"),
P_mean = c(0.86, 1.74, 1.14, 1.42),
P_sd = c(0.04, 0.08, 0.04, 0.12),
NO3_mean = c(0.07, 0.12, 0.10, 0.08),
NO3_sd = c(0.004, 0.006, 0.008, 0.01),
NH4_mean = c(1.26, 1.13, 1.22, 1.37),
NH4_sd = c(0.08, 0.06, 0.06, 0.11)
)
# Crear un dataframe vacío para almacenar los resultados
data_expanded <- data.frame()
# Iterar sobre cada fila del dataframe original y crear las repeticiones
for (i in 1:nrow(data)) {
# Para cada variable (P, NO3-N, NH4+-N), generar las tres repeticiones
temp <- data.frame(
Fecha = rep("2013", 9),  # Ajuste de fecha para el año del estudio
Intensidad_Pastoreo = rep(data$Intensidad_Pastoreo[i], 9),
Psuelo = rep(c("P", "NO3-N", "NH4+-N"), each = 3),
Valor = c(
data$P_mean[i] - data$P_sd[i], data$P_mean[i], data$P_mean[i] + data$P_sd[i],
data$NO3_mean[i] - data$NO3_sd[i], data$NO3_mean[i], data$NO3_mean[i] + data$NO3_sd[i],
data$NH4_mean[i] - data$NH4_sd[i], data$NH4_mean[i], data$NH4_mean[i] + data$NH4_sd[i]
)
)
# Añadir los datos temporales al dataframe expandido
data_expanded <- rbind(data_expanded, temp)
}
# Mostrar el dataframe expandido
print(data_expanded)
data_expanded$Fecha = NULL
# Ordenar el dataframe expandido por la columna "Variable"
data_expanded <- arrange(data_expanded, Psuelo)
# Reorganizar las columnas para que "Variable" sea la primera
data_expanded <- select(data_expanded, Psuelo, everything())
# Mostrar el dataframe resultante
print(data_expanded)
# Asegurarse de que los factores estén correctamente definidos
data_expanded$Intensidad_Pastoreo <- as.factor(data_expanded$Intensidad_Pastoreo)
data_expanded$Psuelo <- as.factor(data_expanded$Psuelo)
# Anova para DBCA
res.aov <- aov(Valor ~ Intensidad_Pastoreo + Psuelo, data = data_expanded)
summary(res.aov)
# Si hay normalidad en nuestros datos
aov_residuals = residuals(res.aov)
shapiro.test(aov_residuals)
# QQ-plot para verificar normalidad
qqPlot(aov_residuals, main = "QQ-Plot de Residuos")
bartlett.test(Valor ~ Intensidad_Pastoreo, data = data_expanded)
bartlett.test(Valor ~ Psuelo, data = data_expanded)
# Durbin-Watson test
lmtest::dwtest(res.aov)
tukeyMetodo1 = HSD.test(res.aov, "Intensidad_Pastoreo", alpha = 0.05, group = T)
plot(tukeyMetodo1, variation = "IQR")
tukeyMetodo1
print(tukeyMetodo1)
tukeyMetodo2 = HSD.test(res.aov, "Psuelo", alpha = 0.05, group = T)
print(tukeyMetodo2)
tukeyMetodo2 = HSD.test(res.aov, "Psuelo", alpha = 0.05, group = T)
plot(tukeyMetodo2, variation = "IQR")
plot(tukeyMetodo1, variation = "IQR")
tukeyMetodo1 = HSD.test(res.aov, "Intensidad_Pastoreo", alpha = 0.05, group = T)
tukeyMetodo1
2600/4
# Cargamos las librerías necesarias
library(tidyr)
library(dplyr)
library(agricolae)
# Cargar la librería ggplot2
library(ggplot2)
library(lmtest)
library(car) # Para la verificación de suposiciones
# Crear el dataframe original con los valores medios y la desviación estándar
data <- data.frame(
Tratamiento = c("N0", "N20", "N40", "N60", "N80"),
Nmin_mean = c(30.4, 29.0, 26.7, 26.9, 32.8),
Nmin_sd = c(1.8, 2.3, 1.2, 1.9, 4.3),
NO3_mean = c(4.8, 5.5, 4.4, 4.4, 6.5),
NO3_sd = c(1.3, 0.5, 0.4, 1.1, 1.1),
NH4_mean = c(25.6, 23.5, 21.3, 22.5, 26.3),
NH4_sd = c(0.9, 1.9, 1.2, 1.2, 3.4)
)
# Crear un dataframe vacío para almacenar los resultados
data_expanded <- data.frame()
# Iterar sobre cada fila del dataframe original y crear las repeticiones
for (i in 1:nrow(data)) {
# Para cada variable (Nmin, NO3-N, NH4+-N), generar las tres repeticiones
temp <- data.frame(
Fecha = rep("2018-05-29", 9),
Tratamiento = rep(data$Tratamiento[i], 9),
Variable = rep(c("Nmin", "NO3-N", "NH4+-N"), each = 3),
Valor = c(
data$Nmin_mean[i] - data$Nmin_sd[i], data$Nmin_mean[i], data$Nmin_mean[i] + data$Nmin_sd[i],
data$NO3_mean[i] - data$NO3_sd[i], data$NO3_mean[i], data$NO3_mean[i] + data$NO3_sd[i],
data$NH4_mean[i] - data$NH4_sd[i], data$NH4_mean[i], data$NH4_mean[i] + data$NH4_sd[i]
)
)
# Añadir los datos temporales al dataframe expandido
data_expanded <- rbind(data_expanded, temp)
}
data_expanded$Fecha = NULL
# Ordenar el dataframe expandido por la columna "Variable"
data_expanded <- arrange(data_expanded, Variable)
# Reorganizar las columnas para que "Variable" sea la primera
data_expanded <- select(data_expanded, Variable, everything())
# Mostrar el dataframe resultante
print(data_expanded)
datos_largos =  data_expanded
names(datos_largos) = c('Emisores','Tratamiento','N2O')
datos_largos$Emisores = as.factor(datos_largos$Emisores)
#Anova
res.aov <- aov(N2O ~ Emisores, data = datos_largos)
summary(res.aov)
# Si hay normalidad en nuestros datos
aov_residuals = residuals(res.aov)
shapiro.test(aov_residuals) #datos normales ya que p valor + 0.05
#QQ-plot para verificar normalidad
qqPlot(aov_residuals, main = "QQ-Plot de Residuos")
bartlett.test(N2O ~ Emisores, data = datos_largos) #homoceasticidad
#Durbin-Watson test
lmtest::dwtest(res.aov) # no hay autocorrelacion
tukeyMetodo2 = HSD.test(res.aov,"Emisores", alpha =0.05, group=T)
plot(tukeyMetodo2,variation="IQR")
View(datos_largos)
grouped_data <- datos_largos %>%
group_by(Emisores) %>%
summarise(y_bar_i = mean(N2O), S_i = sd(N2O))
grouped_data
grouped_data <- grouped_data %>%
mutate(ln_y_bar_i = log(y_bar_i), ln_S_i = log(S_i))
# Plot ln(S_i) against ln(y_bar_i)
plot(grouped_data$ln_y_bar_i, grouped_data$ln_S_i,
xlab = expression(ln(bar(y)[i])), ylab = expression(ln(S[i])),
main = "Plot of ln(S_i) against ln(y_bar_i)",
pch = 19, col = "blue")
# Adding a linear regression line
model <- lm(ln_S_i ~ ln_y_bar_i, data = grouped_data)
abline(model, col = "red")
print(model)
# Extract coefficients
intercept <- round(coef(model)[1], 2)  # intercept
slope <- round(coef(model)[2], 2)      # slope
# Create the equation text
equation <- paste0("ln(S_i) = ", intercept, " + ", slope, " * ln(y_bar_i)")
# Add the equation to the plot
text(x = min(grouped_data$ln_y_bar_i), y = max(grouped_data$ln_S_i),
labels = equation, pos = 4, col = "red")
# Calculate alpha and lambda
alpha <- model$coefficients[2]
landa <- 1 - alpha
landa
datos_largos$transform = sqrt(datos_largos$N2O)
datos_largos$Emisores = as.factor(datos_largos$Emisores)
res.aov2 <- aov(transform ~ Emisores, data = datos_largos)
datos=read.table("1. Correlacion.csv", header = T,  sep=";",  dec="."     )
setwd("~/GitHub/Diseno_experimental/tarea8")
setwd("~/GitHub/Diseno_experimental/tarea8")
datos=read.table("datos.csv", header = T,  sep=";",  dec="."     )
head(datos)
str(datos)
# Gráfico de cajas
par(mfrow=c(1,1))
boxplot(datos[,1:4],main="Diagrama de cajas",
xlab="Variables con diferentes unidades",
ylab="Puntaje",
col=c("springgreen1","yellow","tomato","pink"))
# Calculos y graficos de correlaciones
# Correlacion de Pearson
midato=cor(datos,method="pearson")
cat("Correlacion de Pearson\n")
print(midato)
# H0: Rho=0
prueba=cor.test(datos$Sabor,datos$AA,method="pearson")
print(prueba)
# De otra manera
plot(datos$AA,datos$Sabor,main="Grafica de Dispersion",col="blue")
segments(4,0,6.8,40,col="17")
cor(datos)
cor(datos)[1,2]
cor.test(datos$Sabor,datos$AA)
# Graficos de Correlacion
data2=datos
library(corrplot)
i=cor(data2,method="pearson")
corrplot(i,sig.level=0.05,type="lower")
