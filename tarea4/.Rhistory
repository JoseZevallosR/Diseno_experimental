scale_fill_manual(values =  Mypal,labels=legenda,name=NULL)+
coord_equal()+geom_path(data = shapefile_df,aes(x = long, y = lat, group = group),color = 'black', size = .5)
}
graficoVS=function(y,obs,sim){
df=data.frame(y,obs,sim)
names(df)=c('y','obs','sim')
df=mutate(df,Location=factor(case_when(y>-19   & y<=-12.7 ~'Costa sur',
y>-12.7 & y<=-6.4  ~ 'Costa central',
y>-6.4  & y<=0     ~'Costa norte')))
#ggplot(df, aes(x = obs, y = sim,colour=Location))
img=ggplot(df, aes(x = obs, y = sim))+geom_point(size=2, shape=20)+geom_abline(intercept = 0)
#leyenda=g_legend(img)
img=img+theme(legend.position="none")+theme(axis.title.x=element_blank(),
axis.ticks.x=element_blank(),
axis.title.y=element_blank(),
axis.ticks.y=element_blank())
leyenda=0
list(img,leyenda)
}
plot_comparison=function(gauge_stat,simulated_stats,file_save_name,language='Spanish'){
if (language == 'Spanish'){
c(img11,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean24,simulated_stats$mean24)
img11=img11+labs(title='Promedio (mm)')+theme(plot.title = element_text(hjust = 0.5,size=10))
img12=graficoVS(gauge_stats$y,gauge_stats$var24,simulated_stats$var24)[[1]]
img12=img12+labs(title='Varianza')+theme(plot.title = element_text(hjust = 0.5,size=10))
img13=graficoVS(gauge_stats$y,gauge_stats$autocov24,simulated_stats$autocov24)[[1]]
img13=img13+labs(title='Lag-1 Autocovarianza')+theme(plot.title = element_text(hjust = 0.5,size=10))
img14=graficoVS(gauge_stats$y,gauge_stats$dryperiod24,simulated_stats$dryperiod24)[[1]]
img14=img14+labs(title='Probabilidad de 0 lluvia')+theme(plot.title = element_text(hjust = 0.5,size=10))
c(img21,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean3,simulated_stats$mean3)
img22=graficoVS(gauge_stats$y,gauge_stats$var3,simulated_stats$var3)[[1]]
img23=graficoVS(gauge_stats$y,gauge_stats$autocov3,simulated_stats$autocov3)[[1]]
img24=graficoVS(gauge_stats$y,gauge_stats$dryperiod3,simulated_stats$dryperiod3)[[1]]
c(img31,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean6,simulated_stats$mean6)
img32=graficoVS(gauge_stats$y,gauge_stats$var6,simulated_stats$var6)[[1]]
img33=graficoVS(gauge_stats$y,gauge_stats$autocov6,simulated_stats$autocov6)[[1]]
img34=graficoVS(gauge_stats$y,gauge_stats$dryperiod6,simulated_stats$dryperiod6)[[1]]
c(img41,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean12,simulated_stats$mean12)
img42=graficoVS(gauge_stats$y,gauge_stats$var12,simulated_stats$var12)[[1]]
img43=graficoVS(gauge_stats$y,gauge_stats$autocov12,simulated_stats$autocov12)[[1]]
img44=graficoVS(gauge_stats$y,gauge_stats$dryperiod12,simulated_stats$dryperiod12)[[1]]
bottom <- textGrob("Precipitaci?n diaria", gp = gpar(fontsize = 9))
left <- textGrob('CV Simulado 24-Horas Nivel acum ', gp = gpar(fontsize = 9),rot = 90)
p1=arrangeGrob(img11,img12,img13,img14,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulado 3-Horas Nivel acum ', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM sesgo corregido", gp = gpar(fontsize = 10))
p2=arrangeGrob(img21,img22,img23,img24,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulado 6-Horas Nivel acum ', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM sesgo corregido", gp = gpar(fontsize = 10))
p3=arrangeGrob(img31,img32,img33,img34,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulado 12-Horas Nivel acum ', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM sesgo corregido", gp = gpar(fontsize = 10))
p4=arrangeGrob(img41,img42,img43,img44,nrow = 1,ncol = 4,bottom = bottom,left = left)
}else{
c(img11,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean24,simulated_stats$mean24)
img11=img11+labs(title='Mean Rainfall (mm)')+theme(plot.title = element_text(hjust = 0.5,size=10))
img12=graficoVS(gauge_stats$y,gauge_stats$var24,simulated_stats$var24)[[1]]
img12=img12+labs(title='Variance')+theme(plot.title = element_text(hjust = 0.5,size=10))
img13=graficoVS(gauge_stats$y,gauge_stats$autocov24,simulated_stats$autocov24)[[1]]
img13=img13+labs(title='Lag-1 Autocovariance')+theme(plot.title = element_text(hjust = 0.5,size=10))
img14=graficoVS(gauge_stats$y,gauge_stats$dryperiod24,simulated_stats$dryperiod24)[[1]]
img14=img14+labs(title='Probability of 0 Rain')+theme(plot.title = element_text(hjust = 0.5,size=10))
c(img21,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean3,simulated_stats$mean3)
img22=graficoVS(gauge_stats$y,gauge_stats$var3,simulated_stats$var3)[[1]]
img23=graficoVS(gauge_stats$y,gauge_stats$autocov3,simulated_stats$autocov3)[[1]]
img24=graficoVS(gauge_stats$y,gauge_stats$dryperiod3,simulated_stats$dryperiod3)[[1]]
c(img31,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean6,simulated_stats$mean6)
img32=graficoVS(gauge_stats$y,gauge_stats$var6,simulated_stats$var6)[[1]]
img33=graficoVS(gauge_stats$y,gauge_stats$autocov6,simulated_stats$autocov6)[[1]]
img34=graficoVS(gauge_stats$y,gauge_stats$dryperiod6,simulated_stats$dryperiod6)[[1]]
c(img41,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean12,simulated_stats$mean12)
img42=graficoVS(gauge_stats$y,gauge_stats$var12,simulated_stats$var12)[[1]]
img43=graficoVS(gauge_stats$y,gauge_stats$autocov12,simulated_stats$autocov12)[[1]]
img44=graficoVS(gauge_stats$y,gauge_stats$dryperiod12,simulated_stats$dryperiod12)[[1]]
bottom <- textGrob("Daily rain gauge", gp = gpar(fontsize = 9))
left <- textGrob('CV Simulated 24-Hourly Acc Level', gp = gpar(fontsize = 9),rot = 90)
p1=arrangeGrob(img11,img12,img13,img14,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulated 3-Hourly Acc Level', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM bias corrected", gp = gpar(fontsize = 10))
p2=arrangeGrob(img21,img22,img23,img24,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulated 6-Hourly Acc Level', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM bias corrected", gp = gpar(fontsize = 10))
p3=arrangeGrob(img31,img32,img33,img34,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulated 12-Hourly Acc Level', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM bias corrected", gp = gpar(fontsize = 10))
p4=arrangeGrob(img41,img42,img43,img44,nrow = 1,ncol = 4,bottom = bottom,left = left)
}
figure=grid.arrange(p1,p2,p3,p4,nrow=4)
ggsave(file_save_name,figure,dpi=1200,units = 'cm',width =20 ,height =25 )
figure
}
maps_plot=function(file1,file2,file3,file4,file5,file6,intervals,file_save_name){
a=expression(alpha)
l=expression(paste(lambda,'(1/hr)'))
v=expression(paste(upsilon,'(hr)'))
k=expression(kappa)
phi=expression(phi)
u=expression(paste(mu,'(mm/hr)'))
c(df.map,legenda):=raster_to_df(file1,intervals)
mapa1=plot_map(df.map,legenda,titulo = a)
c(df.map,legenda):=raster_to_df(file2,intervals)
mapa2=plot_map(df.map,legenda,titulo = l)
c(df.map,legenda):=raster_to_df(file3,intervals)
mapa3=plot_map(df.map,legenda,titulo = v)
c(df.map,legenda):=raster_to_df(file4,intervals)
mapa4=plot_map(df.map,legenda,titulo = k)
c(df.map,legenda):=raster_to_df(file5,intervals)
mapa5=plot_map(df.map,legenda,titulo = phi)
c(df.map,legenda):=raster_to_df(file6,intervals)
mapa6=plot_map(df.map,legenda,titulo = u)
figure1=grid.arrange(arrangeGrob(mapa1,mapa2,mapa3,mapa4,mapa5,mapa6,nrow = 3))
ggsave(file_save_name,figure1,dpi=1200,units = 'cm',width =20 ,height =25 )
}
plot_cdf=function(file,par,titule,language='English'){
obs=data.frame(obs=nonzero(read.csv(file,sep = ',')$Rainfall.mm))
sim=data.frame(sim=nonzero(precp_sim(as.numeric(par),dim(obs)[1],tscale = 3)))
x=c(obs$obs,sim$sim)
g=c(rep(1,length(obs$obs)),rep(2,length(sim$sim)))
df=data.frame(x,g=factor(g))
if (language=='Spanish'){
ggplot(df,aes(x,colour=g))+stat_ecdf(geom = "point")+stat_ecdf(geom = "point")+
labs(color="Legend",title = titule,x='Acumulado 3 horas (mm)',y='CDF')+theme(legend.margin=margin(t = 0, unit='cm'),legend.title=element_blank(),plot.title = element_text(hjust = 0.5),legend.position = c(0.8, 0.25))+
scale_color_manual(labels = c("Observado", "Simulado"), values = c("red", "blue"))
}else{
ggplot(df,aes(x,colour=g))+stat_ecdf(geom = "point")+stat_ecdf(geom = "point")+
labs(color="Legend",title = titule,x='Three hourly (mm)',y='CDF')+theme(legend.margin=margin(t = 0, unit='cm'),legend.title=element_blank(),plot.title = element_text(hjust = 0.5),legend.position = c(0.8, 0.25))+
scale_color_manual(labels = c("Observed", "Synthetic"), values = c("red", "blue"))
}
}
opt='TRMM'
if (opt=='TRMM'){
#Mixed stats from gauge stations and corrected TRMM
gauge_stats=read.csv('D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/data/feb_gauge_stat.csv')
#gauge_stats=kickOutliers(gauge_stats)
gauge_stats=filter_Neigbors(gauge_stats)
c(nrow,ncol) := dim(gauge_stats)
#Lmin=matrix(c(0.1,0.001,0.001,0.001,0.0854,1),nrow = 6,ncol = nrow)
#Lmax=matrix(c(4,0.1,0.1,0.1,0.1,20),nrow=6,ncol=nrow)
maps=run(rain_stats=gauge_stats,path="D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_parameters/",iterations=5,FILE_NAME='parameters_feb.csv')
}else if(opt =='GPM'){
#Mixed stats from gauge stations and corrected TRMM
gauge_stats=read.csv('D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization
/data/gauge_stats.csv')
gauge_stats=kickOutliers(gauge_stats)
gauge_stats=filter_Neigbors(gauge_stats)
dim(gauge_stats)
maps=run(rain_stats=gauge_stats,path="D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization
/output/CV_parameters/",iterations=20)
}
source('D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/src/InterpolationFunctions.R')
library(raster)
grd=readRDS('D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/data/grilla.rds')
path_to_file='D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_parameters/parameters_feb.csv'
mapas_mes(path_to_file = path_to_file,grd,month = 'feb')
source('D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/src/plotHelpers.R')
Peru <- shapefile("d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/data/Departamento_INEI_2017.shp")
# Next the shapefile has to be converted to a dataframe for use in ggplot2
shapefile_df <- fortify(Peru)
a=expression(alpha)
l=expression(paste(lambda,'(1/hr)'))
v=expression(paste(upsilon,'(hr)'))
k=expression(kappa)
phi=expression(phi)
u=expression(paste(mu,'(mm/hr)'))
#feb
dir1='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_1_feb.tif'
dir2='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_2_feb.tif'
dir3='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_3_feb.tif'
dir4='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_4_feb.tif'
dir5='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_5_feb.tif'
dir6='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_6_feb.tif'
c(df.map,legenda):=raster_to_df(dir1,10)
mapa1=plot_map(df.map,legenda,titulo = a,shapefile_df)
c(df.map,legenda):=raster_to_df(dir2,10)
mapa2=plot_map(df.map,legenda,titulo = l,shapefile_df)
c(df.map,legenda):=raster_to_df(dir3,10)
mapa3=plot_map(df.map,legenda,titulo = v,shapefile_df)
c(df.map,legenda):=raster_to_df(dir4,10)
mapa4=plot_map(df.map,legenda,titulo = k,shapefile_df)
c(df.map,legenda):=raster_to_df(dir5,10)
mapa5=plot_map(df.map,legenda,titulo = phi,shapefile_df)
c(df.map,legenda):=raster_to_df(dir6,10)
mapa6=plot_map(df.map,legenda,titulo = u,shapefile_df)
figure1=grid.arrange(arrangeGrob(mapa1,mapa2,mapa3,mapa4,mapa5,mapa6,nrow = 3))
ggsave("D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/img/parameters_february.png",figure1,dpi=1200,units = 'cm',width =20 ,height =25 )
library(raster)
a=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_1_feb.tif')
v=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_3_feb.tif')
fi=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_5_feb.tif')
k=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_4_feb.tif')
l=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_2_feb.tif')
mu=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_6_feb.tif')
average_rain_cell_duration=v/a
average_number_cell_per_storn=1+k/fi
average_storm_duration=v/(fi*a)#
average_rainfall_deph_storm=mu*(v/a)*(1+k/fi)
writeRaster(average_rain_cell_duration,'d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_rain_cell_duration.tif',overwrite=T)
writeRaster(average_storm_duration,'d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_storm_duration.tif',overwrite=T)
writeRaster(average_rainfall_deph_storm,'d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_rainfall_deph_storm.tif',overwrite=T)
writeRaster(average_number_cell_per_storn,'d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_number_cell_per_storn.tif',overwrite=T)
c(df.map,legenda):=raster_to_df('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_number_cell_per_storn.tif',6)
mapa1=plot_map(df.map,legenda,titulo = '(a) Average number \n of rain cell per storm',shapefile_df)
c(df.map,legenda):=raster_to_df('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_rain_cell_duration.tif',6)
mapa2=plot_map(df.map,legenda,titulo = '(b) Average duration \n of rain cell (hr)',shapefile_df)
c(df.map,legenda):=raster_to_df('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_storm_duration.tif',6)
mapa3=plot_map(df.map,legenda,titulo = '(c) Average rainfall \n duration (hr)',shapefile_df)
c(df.map,legenda):=raster_to_df('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_rainfall_deph_storm.tif',6)
mapa4=plot_map(df.map,legenda,titulo = '(d) Average rain deph \n per storm (mm)',shapefile_df)
figure2=grid.arrange(arrangeGrob(mapa1,mapa2,mapa3,mapa4,nrow = 2))
ggsave("D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/img/storm_characteristics.png",figure2,dpi=1200,units = 'cm',width =20 ,height =20 )
1+2
5*9
1
1.2
TRUE
FALSE
True
TRUE
FALSE
1+1
1*2
1/9
3**2
3^2
5**3
"Hola mundo"
Hola mundo
3**2
3**2
9+9
3**2
9+9
3**2
9+9
3**2
9+9
x = 8
x+x
2*x
x**2
x**3
x = 8
x = 9
x
cuadrado = function(x){
return(x**2)
}
cuadrado = function(x){
# Esta funcion sirve para elevar numeros al cuadrado
return(x**2)
}
cuadrado(9)
3**2
cuadrado(8)
cuadrado(7)
Cuadrado(1)
potencia = function(x,n){
return(x**n)
}
potencia = function(x,n){
return(x**n)
}
return(x**n)
potencia(7,3)
potencia(8,5)
Potencia(1,1)
potencia(8,7)
install.packages("plotly")
library(plotly)
library(plotly)
library(plotly)
library(plotly)
library(plumber)
detach("package:plumber", unload = TRUE)
library(raster)
library(plotly)
USPersonalExpenditure <- data.frame("Categorie"=rownames(USPersonalExpenditure), USPersonalExpenditure)
x = 1
x
x <- 2
x
View(USPersonalExpenditure)
USPersonalExpenditure
USPersonalExpenditure[,'Categorie']
c(1,2,3)
c("a","b","c")
USPersonalExpenditure[,c('Categorie','X1940')]
data = USPersonalExpenditure[,c('Categorie', 'X1960')]
data
fig = plotly::plot_ly(data, labels = ~Categorie, values = ~X1960, type = 'pie')
fig = fig %>% layout(title = 'United States Personal Expenditures by Categories in 1960',
xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
fig
# Load the plotly library
library(plotly)
# Create sample data
data <- data.frame(
category = c("A", "B", "C", "D"),
values = c(23, 17, 35, 29)
)
# Create a bar chart
fig <- plot_ly(
data,
x = ~category,
y = ~values,
type = 'bar',
marker = list(color = 'rgba(58, 71, 80, 0.6)', line = list(color = 'rgba(58, 71, 80, 1.0)', width = 1.5))
)
# Add titles
fig <- fig %>%
layout(
title = "Sample Bar Chart",
xaxis = list(title = "Category"),
yaxis = list(title = "Values")
)
# Display the plot
fig
setwd("D:/Doctorado/Experimental")
library(lmtest)
library(agricolae)
data = read.csv(file = "bauermcnett.csv",sep = ';')
str(data)
data$Especie <- as.factor(data$Especie)
data$Tratamiento <- as.factor(data$Tratamiento)
data$Malla <- as.factor(data$Malla)
str(data)
res.aov = aov(WRV ~ Especie + Tratamiento + Malla , data = data)
print(reas.aov)
# Si hay normalidad en nuestros datos
aov_residuals = residuals(res.aov)
shapiro.test(aov_residuals)
# Homosteasis
#se mantiene la hipotesis de homogeneidad en agrupamiento por especie
bartlett.test(WRV ~ Especie, data = data)
#se mantiene la hipotesis de homogeneidad en agrupamiento por tratamiento
bartlett.test(WRV ~ Tratamiento, data = data)
# si se puede rechazar la hipotesis nula de homogeneidad de varianzas
bartlett.test(WRV ~ Malla, data = data)
#Durbin-Watson test
lmtest::dwtest(res.aov)
TukeyMetodo <- HSD.test(res.aov, "Malla", alpha = 0.05, group = T)
TukeyMetodo
# 1. Histograma de residuos
ggplot(data.frame(aov_residuals), aes(x = aov_residuals)) +
geom_histogram(binwidth = 0.5, color = "black", fill = "lightblue") +
labs(title = "Histograma de Residuos", x = "Residuos", y = "Frecuencia") +
theme_minimal()
# 2. QQ-plot para verificar normalidad
qqPlot(aov_residuals, main = "QQ-Plot de Residuos")
library(ggplot2) # Para la creación de gráficos
library(car) # Para la verificación de suposiciones
install.packages("car")
setwd("D:/Doctorado/Experimental")
library(lmtest)
library(agricolae)
library(ggplot2) # Para la creación de gráficos
library(car) # Para la verificación de suposiciones
data = read.csv(file = "bauermcnett.csv",sep = ';')
str(data)
data$Especie <- as.factor(data$Especie)
data$Tratamiento <- as.factor(data$Tratamiento)
data$Malla <- as.factor(data$Malla)
str(data)
res.aov = aov(WRV ~ Especie + Tratamiento + Malla , data = data)
print(reas.aov)
print(res.aov)
# Si hay normalidad en nuestros datos
aov_residuals = residuals(res.aov)
shapiro.test(aov_residuals)
# Homosteasis
#se mantiene la hipotesis de homogeneidad en agrupamiento por especie
bartlett.test(WRV ~ Especie, data = data)
#se mantiene la hipotesis de homogeneidad en agrupamiento por tratamiento
bartlett.test(WRV ~ Tratamiento, data = data)
# si se puede rechazar la hipotesis nula de homogeneidad de varianzas
bartlett.test(WRV ~ Malla, data = data)
#Durbin-Watson test
lmtest::dwtest(res.aov)
TukeyMetodo <- HSD.test(res.aov, "Malla", alpha = 0.05, group = T)
TukeyMetodo
# 1. Histograma de residuos
ggplot(data.frame(aov_residuals), aes(x = aov_residuals)) +
geom_histogram(binwidth = 0.5, color = "black", fill = "lightblue") +
labs(title = "Histograma de Residuos", x = "Residuos", y = "Frecuencia") +
theme_minimal()
# 2. QQ-plot para verificar normalidad
qqPlot(aov_residuals, main = "QQ-Plot de Residuos")
# 3. Gráfico de dispersión de residuos vs valores ajustados
fitted_values <- fitted(res.aov)
ggplot(data.frame(Fitted = fitted_values, Residuals = aov_residuals), aes(x = Fitted, y = Residuals)) +
geom_point() +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Gráfico de Residuos vs Valores Ajustados", x = "Valores Ajustados", y = "Residuos") +
theme_minimal()
# 4. Gráfico de medias con intervalo de confianza para el análisis de Tukey
Tukey_plot_data <- data.frame(Treatment = rownames(TukeyMetodo$groups),
Mean = TukeyMetodo$means[,1],
Lower = TukeyMetodo$means[,1] - TukeyMetodo$means[,2],
Upper = TukeyMetodo$means[,1] + TukeyMetodo$means[,2])
ggplot(Tukey_plot_data, aes(x = Treatment, y = Mean)) +
geom_point(size = 3) +
geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.2) +
labs(title = "Intervalo de Confianza de Tukey para las Medias", x = "Tratamiento (Malla)", y = "Media WRV") +
theme_minimal()
View(data)
View(data)
setwd("D:/Doctorado/Experimental")
library(lmtest)
library(agricolae)
library(ggplot2) # Para la creación de gráficos
library(car) # Para la verificación de suposiciones
data = read.csv(file = "bauermcnett.csv",sep = ';')
str(data)
data = read.csv(file = "bauermcnett.csv",sep = ';')
data
setwd("D:/Proyectos_GitHub/Diseno_experimental/tarea4/")
library(lmtest)
library(agricolae)
library(ggplot2) # Para la creación de gráficos
library(car) # Para la verificación de suposiciones
data = read.csv(file = "bauermcnett.csv",sep = ';')
str(data)
data$Especie <- as.factor(data$Especie)
data$Tratamiento <- as.factor(data$Tratamiento)
data$Malla <- as.factor(data$Malla)
str(data)
res.aov = aov(peso ~ Especie + Tratamiento + Malla , data = data)
print(res.aov)
res.aov = aov(peso ~ Especie + Tratamiento + Malla , data = data)
str(data)
res.aov = aov(Peso ~ Especie + Tratamiento + Malla , data = data)
print(res.aov)
res.aov = aov(Peso ~ Especie + Tratamiento + Malla , data = data)
print(res.aov)
print(res.aov)
# Homosteasis
#se mantiene la hipotesis de homogeneidad en agrupamiento por especie
bartlett.test(Peso ~ Especie, data = data)
#se mantiene la hipotesis de homogeneidad en agrupamiento por tratamiento
bartlett.test(Peso ~ Tratamiento, data = data)
# si se puede rechazar la hipotesis nula de homogeneidad de varianzas
bartlett.test(Peso ~ Malla, data = data)
# Homosteasis
#se mantiene la hipotesis de homogeneidad en agrupamiento por especie
bartlett.test(Peso ~ Especie, data = data)
bartlett.test(Peso ~ Especie, data = data)
bartlett.test(Peso ~ Tratamiento, data = data)
bartlett.test(Peso ~ Malla, data = data)
#Durbin-Watson test
lmtest::dwtest(res.aov)
print(TukeyMetodo)
setwd("D:/Proyectos_GitHub/Diseno_experimental/tarea4/")
library(lmtest)
library(agricolae)
library(ggplot2) # Para la creación de gráficos
library(car) # Para la verificación de suposiciones
data = read.csv(file = "bauermcnett.csv",sep = ';')
str(data)
data$Especie <- as.factor(data$Especie)
data$Tratamiento <- as.factor(data$Tratamiento)
data$Malla <- as.factor(data$Malla)
str(data)
res.aov = aov(Peso ~ Especie + Tratamiento + Malla , data = data)
print(res.aov)
# Si hay normalidad en nuestros datos
aov_residuals = residuals(res.aov)
shapiro.test(aov_residuals)
# Homosteasis
bartlett.test(Peso ~ Especie, data = data)
bartlett.test(Peso ~ Tratamiento, data = data)
bartlett.test(Peso ~ Malla, data = data)
#Durbin-Watson test
lmtest::dwtest(res.aov)
#Tukey DBCA
TukeyMetodo <- HSD.test(res.aov, "Malla", alpha = 0.05, group = T)
print(TukeyMetodo)
# 2. QQ-plot para verificar normalidad
qqPlot(aov_residuals, main = "QQ-Plot de Residuos")
fitted_values <- fitted(res.aov)
ggplot(data.frame(Fitted = fitted_values, Residuals = aov_residuals), aes(x = Fitted, y = Residuals)) +
geom_point() +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Gráfico de Residuos vs Valores Ajustados", x = "Valores Ajustados", y = "Residuos") +
theme_minimal()
# 4. Gráfico de medias con intervalo de confianza para el análisis de Tukey
Tukey_plot_data <- data.frame(Treatment = rownames(TukeyMetodo$groups),
Mean = TukeyMetodo$means[,1],
Lower = TukeyMetodo$means[,1] - TukeyMetodo$means[,2],
Upper = TukeyMetodo$means[,1] + TukeyMetodo$means[,2])
ggplot(Tukey_plot_data, aes(x = Treatment, y = Mean)) +
geom_point(size = 3) +
geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.2) +
labs(title = "Intervalo de Confianza de Tukey para las Medias", x = "Tratamiento (Malla)", y = "Media WRV") +
theme_minimal()
ggplot(Tukey_plot_data, aes(x = Treatment, y = Mean)) +
geom_point(size = 3) +
geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.2) +
labs(title = "Intervalo de Confianza de Tukey para las Medias", x = "Tratamiento (Malla)", y = "Media Peso") +
theme_minimal()
aov_residuals = residuals(res.aov)
shapiro.test(aov_residuals)
res.aov = aov(Peso ~ Especie + Tratamiento + Malla , data = data)
print(res.aov)
res.aov = aov(Peso ~ Especie + Tratamiento + Malla , data = data)
print(res.aov)
print(res.aov)
#Durbin-Watson test
lmtest::dwtest(res.aov)
#Durbin-Watson test
dw = lmtest::dwtest(res.aov)
print(dw)
