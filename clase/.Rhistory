seq(min(vector),max(vector),length.out=n)
}
reclass_raster=function(breaks){
n=length(breaks)
class_matrix=matrix(data=NA,nrow = n-1,ncol = 3)
count=0
legenda=c()
for (i in 1:(n-1)){
count=count+1
class_matrix[i,]=c(breaks[i],breaks[i+1],count)
legenda=c(legenda,paste(as.character(round(breaks[i],2)),as.character(round(breaks[i+1],2)),sep = '-'))
}
list(matt=class_matrix,legends=legenda)
}
map = raster(dir)
c(matt,legenda):=reclass_raster(breaks = breaks_df(na.omit(values(map)),n))
map = reclassify(map,matt,include.lowest=TRUE)
map.p=rasterToPoints(map)
df <- data.frame(map.p)
colnames(df) = c("Longitude", "Latitude", "MAP")
list(df=df,legenda=legenda)
}
plot_map=function(df.map,legenda,titulo,shapefile_df){
#Mypal=gray.colors(length(legenda))
Mypal=topo.colors(length(legenda))
#number of intervals
ggplot(data=df.map, aes(y=Latitude, x=Longitude)) +
geom_raster(aes(fill=factor(MAP))) +scale_x_continuous(limits = c(-82.0,-67.5),breaks= scales::pretty_breaks(n=4))+
theme(axis.text.x = element_text(size=10),legend.key.height = unit(0.5, 'cm'),legend.text = element_text(size=10),legend.position="left",plot.title = element_text(hjust = 0.5))+ggtitle(titulo)+
scale_fill_manual(values =  Mypal,labels=legenda,name=NULL)+
coord_equal()+geom_path(data = shapefile_df,aes(x = long, y = lat, group = group),color = 'black', size = .5)
}
graficoVS=function(y,obs,sim){
df=data.frame(y,obs,sim)
names(df)=c('y','obs','sim')
df=mutate(df,Location=factor(case_when(y>-19   & y<=-12.7 ~'Costa sur',
y>-12.7 & y<=-6.4  ~ 'Costa central',
y>-6.4  & y<=0     ~'Costa norte')))
#ggplot(df, aes(x = obs, y = sim,colour=Location))
img=ggplot(df, aes(x = obs, y = sim))+geom_point(size=2, shape=20)+geom_abline(intercept = 0)
#leyenda=g_legend(img)
img=img+theme(legend.position="none")+theme(axis.title.x=element_blank(),
axis.ticks.x=element_blank(),
axis.title.y=element_blank(),
axis.ticks.y=element_blank())
leyenda=0
list(img,leyenda)
}
plot_comparison=function(gauge_stat,simulated_stats,file_save_name,language='Spanish'){
if (language == 'Spanish'){
c(img11,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean24,simulated_stats$mean24)
img11=img11+labs(title='Promedio (mm)')+theme(plot.title = element_text(hjust = 0.5,size=10))
img12=graficoVS(gauge_stats$y,gauge_stats$var24,simulated_stats$var24)[[1]]
img12=img12+labs(title='Varianza')+theme(plot.title = element_text(hjust = 0.5,size=10))
img13=graficoVS(gauge_stats$y,gauge_stats$autocov24,simulated_stats$autocov24)[[1]]
img13=img13+labs(title='Lag-1 Autocovarianza')+theme(plot.title = element_text(hjust = 0.5,size=10))
img14=graficoVS(gauge_stats$y,gauge_stats$dryperiod24,simulated_stats$dryperiod24)[[1]]
img14=img14+labs(title='Probabilidad de 0 lluvia')+theme(plot.title = element_text(hjust = 0.5,size=10))
c(img21,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean3,simulated_stats$mean3)
img22=graficoVS(gauge_stats$y,gauge_stats$var3,simulated_stats$var3)[[1]]
img23=graficoVS(gauge_stats$y,gauge_stats$autocov3,simulated_stats$autocov3)[[1]]
img24=graficoVS(gauge_stats$y,gauge_stats$dryperiod3,simulated_stats$dryperiod3)[[1]]
c(img31,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean6,simulated_stats$mean6)
img32=graficoVS(gauge_stats$y,gauge_stats$var6,simulated_stats$var6)[[1]]
img33=graficoVS(gauge_stats$y,gauge_stats$autocov6,simulated_stats$autocov6)[[1]]
img34=graficoVS(gauge_stats$y,gauge_stats$dryperiod6,simulated_stats$dryperiod6)[[1]]
c(img41,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean12,simulated_stats$mean12)
img42=graficoVS(gauge_stats$y,gauge_stats$var12,simulated_stats$var12)[[1]]
img43=graficoVS(gauge_stats$y,gauge_stats$autocov12,simulated_stats$autocov12)[[1]]
img44=graficoVS(gauge_stats$y,gauge_stats$dryperiod12,simulated_stats$dryperiod12)[[1]]
bottom <- textGrob("Precipitaci?n diaria", gp = gpar(fontsize = 9))
left <- textGrob('CV Simulado 24-Horas Nivel acum ', gp = gpar(fontsize = 9),rot = 90)
p1=arrangeGrob(img11,img12,img13,img14,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulado 3-Horas Nivel acum ', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM sesgo corregido", gp = gpar(fontsize = 10))
p2=arrangeGrob(img21,img22,img23,img24,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulado 6-Horas Nivel acum ', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM sesgo corregido", gp = gpar(fontsize = 10))
p3=arrangeGrob(img31,img32,img33,img34,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulado 12-Horas Nivel acum ', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM sesgo corregido", gp = gpar(fontsize = 10))
p4=arrangeGrob(img41,img42,img43,img44,nrow = 1,ncol = 4,bottom = bottom,left = left)
}else{
c(img11,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean24,simulated_stats$mean24)
img11=img11+labs(title='Mean Rainfall (mm)')+theme(plot.title = element_text(hjust = 0.5,size=10))
img12=graficoVS(gauge_stats$y,gauge_stats$var24,simulated_stats$var24)[[1]]
img12=img12+labs(title='Variance')+theme(plot.title = element_text(hjust = 0.5,size=10))
img13=graficoVS(gauge_stats$y,gauge_stats$autocov24,simulated_stats$autocov24)[[1]]
img13=img13+labs(title='Lag-1 Autocovariance')+theme(plot.title = element_text(hjust = 0.5,size=10))
img14=graficoVS(gauge_stats$y,gauge_stats$dryperiod24,simulated_stats$dryperiod24)[[1]]
img14=img14+labs(title='Probability of 0 Rain')+theme(plot.title = element_text(hjust = 0.5,size=10))
c(img21,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean3,simulated_stats$mean3)
img22=graficoVS(gauge_stats$y,gauge_stats$var3,simulated_stats$var3)[[1]]
img23=graficoVS(gauge_stats$y,gauge_stats$autocov3,simulated_stats$autocov3)[[1]]
img24=graficoVS(gauge_stats$y,gauge_stats$dryperiod3,simulated_stats$dryperiod3)[[1]]
c(img31,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean6,simulated_stats$mean6)
img32=graficoVS(gauge_stats$y,gauge_stats$var6,simulated_stats$var6)[[1]]
img33=graficoVS(gauge_stats$y,gauge_stats$autocov6,simulated_stats$autocov6)[[1]]
img34=graficoVS(gauge_stats$y,gauge_stats$dryperiod6,simulated_stats$dryperiod6)[[1]]
c(img41,legenda):=graficoVS(gauge_stats$y,gauge_stats$mean12,simulated_stats$mean12)
img42=graficoVS(gauge_stats$y,gauge_stats$var12,simulated_stats$var12)[[1]]
img43=graficoVS(gauge_stats$y,gauge_stats$autocov12,simulated_stats$autocov12)[[1]]
img44=graficoVS(gauge_stats$y,gauge_stats$dryperiod12,simulated_stats$dryperiod12)[[1]]
bottom <- textGrob("Daily rain gauge", gp = gpar(fontsize = 9))
left <- textGrob('CV Simulated 24-Hourly Acc Level', gp = gpar(fontsize = 9),rot = 90)
p1=arrangeGrob(img11,img12,img13,img14,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulated 3-Hourly Acc Level', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM bias corrected", gp = gpar(fontsize = 10))
p2=arrangeGrob(img21,img22,img23,img24,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulated 6-Hourly Acc Level', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM bias corrected", gp = gpar(fontsize = 10))
p3=arrangeGrob(img31,img32,img33,img34,nrow = 1,ncol = 4,bottom = bottom,left = left)
left <- textGrob('CV Simulated 12-Hourly Acc Level', gp = gpar(fontsize = 9),rot = 90)
bottom <- textGrob("TRMM bias corrected", gp = gpar(fontsize = 10))
p4=arrangeGrob(img41,img42,img43,img44,nrow = 1,ncol = 4,bottom = bottom,left = left)
}
figure=grid.arrange(p1,p2,p3,p4,nrow=4)
ggsave(file_save_name,figure,dpi=1200,units = 'cm',width =20 ,height =25 )
figure
}
maps_plot=function(file1,file2,file3,file4,file5,file6,intervals,file_save_name){
a=expression(alpha)
l=expression(paste(lambda,'(1/hr)'))
v=expression(paste(upsilon,'(hr)'))
k=expression(kappa)
phi=expression(phi)
u=expression(paste(mu,'(mm/hr)'))
c(df.map,legenda):=raster_to_df(file1,intervals)
mapa1=plot_map(df.map,legenda,titulo = a)
c(df.map,legenda):=raster_to_df(file2,intervals)
mapa2=plot_map(df.map,legenda,titulo = l)
c(df.map,legenda):=raster_to_df(file3,intervals)
mapa3=plot_map(df.map,legenda,titulo = v)
c(df.map,legenda):=raster_to_df(file4,intervals)
mapa4=plot_map(df.map,legenda,titulo = k)
c(df.map,legenda):=raster_to_df(file5,intervals)
mapa5=plot_map(df.map,legenda,titulo = phi)
c(df.map,legenda):=raster_to_df(file6,intervals)
mapa6=plot_map(df.map,legenda,titulo = u)
figure1=grid.arrange(arrangeGrob(mapa1,mapa2,mapa3,mapa4,mapa5,mapa6,nrow = 3))
ggsave(file_save_name,figure1,dpi=1200,units = 'cm',width =20 ,height =25 )
}
plot_cdf=function(file,par,titule,language='English'){
obs=data.frame(obs=nonzero(read.csv(file,sep = ',')$Rainfall.mm))
sim=data.frame(sim=nonzero(precp_sim(as.numeric(par),dim(obs)[1],tscale = 3)))
x=c(obs$obs,sim$sim)
g=c(rep(1,length(obs$obs)),rep(2,length(sim$sim)))
df=data.frame(x,g=factor(g))
if (language=='Spanish'){
ggplot(df,aes(x,colour=g))+stat_ecdf(geom = "point")+stat_ecdf(geom = "point")+
labs(color="Legend",title = titule,x='Acumulado 3 horas (mm)',y='CDF')+theme(legend.margin=margin(t = 0, unit='cm'),legend.title=element_blank(),plot.title = element_text(hjust = 0.5),legend.position = c(0.8, 0.25))+
scale_color_manual(labels = c("Observado", "Simulado"), values = c("red", "blue"))
}else{
ggplot(df,aes(x,colour=g))+stat_ecdf(geom = "point")+stat_ecdf(geom = "point")+
labs(color="Legend",title = titule,x='Three hourly (mm)',y='CDF')+theme(legend.margin=margin(t = 0, unit='cm'),legend.title=element_blank(),plot.title = element_text(hjust = 0.5),legend.position = c(0.8, 0.25))+
scale_color_manual(labels = c("Observed", "Synthetic"), values = c("red", "blue"))
}
}
opt='TRMM'
if (opt=='TRMM'){
#Mixed stats from gauge stations and corrected TRMM
gauge_stats=read.csv('D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/data/feb_gauge_stat.csv')
#gauge_stats=kickOutliers(gauge_stats)
gauge_stats=filter_Neigbors(gauge_stats)
c(nrow,ncol) := dim(gauge_stats)
#Lmin=matrix(c(0.1,0.001,0.001,0.001,0.0854,1),nrow = 6,ncol = nrow)
#Lmax=matrix(c(4,0.1,0.1,0.1,0.1,20),nrow=6,ncol=nrow)
maps=run(rain_stats=gauge_stats,path="D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_parameters/",iterations=5,FILE_NAME='parameters_feb.csv')
}else if(opt =='GPM'){
#Mixed stats from gauge stations and corrected TRMM
gauge_stats=read.csv('D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization
/data/gauge_stats.csv')
gauge_stats=kickOutliers(gauge_stats)
gauge_stats=filter_Neigbors(gauge_stats)
dim(gauge_stats)
maps=run(rain_stats=gauge_stats,path="D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization
/output/CV_parameters/",iterations=20)
}
source('D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/src/InterpolationFunctions.R')
library(raster)
grd=readRDS('D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/data/grilla.rds')
path_to_file='D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_parameters/parameters_feb.csv'
mapas_mes(path_to_file = path_to_file,grd,month = 'feb')
source('D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/src/plotHelpers.R')
Peru <- shapefile("d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/data/Departamento_INEI_2017.shp")
# Next the shapefile has to be converted to a dataframe for use in ggplot2
shapefile_df <- fortify(Peru)
a=expression(alpha)
l=expression(paste(lambda,'(1/hr)'))
v=expression(paste(upsilon,'(hr)'))
k=expression(kappa)
phi=expression(phi)
u=expression(paste(mu,'(mm/hr)'))
#feb
dir1='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_1_feb.tif'
dir2='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_2_feb.tif'
dir3='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_3_feb.tif'
dir4='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_4_feb.tif'
dir5='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_5_feb.tif'
dir6='d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_6_feb.tif'
c(df.map,legenda):=raster_to_df(dir1,10)
mapa1=plot_map(df.map,legenda,titulo = a,shapefile_df)
c(df.map,legenda):=raster_to_df(dir2,10)
mapa2=plot_map(df.map,legenda,titulo = l,shapefile_df)
c(df.map,legenda):=raster_to_df(dir3,10)
mapa3=plot_map(df.map,legenda,titulo = v,shapefile_df)
c(df.map,legenda):=raster_to_df(dir4,10)
mapa4=plot_map(df.map,legenda,titulo = k,shapefile_df)
c(df.map,legenda):=raster_to_df(dir5,10)
mapa5=plot_map(df.map,legenda,titulo = phi,shapefile_df)
c(df.map,legenda):=raster_to_df(dir6,10)
mapa6=plot_map(df.map,legenda,titulo = u,shapefile_df)
figure1=grid.arrange(arrangeGrob(mapa1,mapa2,mapa3,mapa4,mapa5,mapa6,nrow = 3))
ggsave("D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/img/parameters_february.png",figure1,dpi=1200,units = 'cm',width =20 ,height =25 )
library(raster)
a=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_1_feb.tif')
v=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_3_feb.tif')
fi=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_5_feb.tif')
k=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_4_feb.tif')
l=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_2_feb.tif')
mu=raster('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/CV_maps/feb/parametros_6_feb.tif')
average_rain_cell_duration=v/a
average_number_cell_per_storn=1+k/fi
average_storm_duration=v/(fi*a)#
average_rainfall_deph_storm=mu*(v/a)*(1+k/fi)
writeRaster(average_rain_cell_duration,'d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_rain_cell_duration.tif',overwrite=T)
writeRaster(average_storm_duration,'d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_storm_duration.tif',overwrite=T)
writeRaster(average_rainfall_deph_storm,'d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_rainfall_deph_storm.tif',overwrite=T)
writeRaster(average_number_cell_per_storn,'d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_number_cell_per_storn.tif',overwrite=T)
c(df.map,legenda):=raster_to_df('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_number_cell_per_storn.tif',6)
mapa1=plot_map(df.map,legenda,titulo = '(a) Average number \n of rain cell per storm',shapefile_df)
c(df.map,legenda):=raster_to_df('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_rain_cell_duration.tif',6)
mapa2=plot_map(df.map,legenda,titulo = '(b) Average duration \n of rain cell (hr)',shapefile_df)
c(df.map,legenda):=raster_to_df('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_storm_duration.tif',6)
mapa3=plot_map(df.map,legenda,titulo = '(c) Average rainfall \n duration (hr)',shapefile_df)
c(df.map,legenda):=raster_to_df('d:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/storm_characteristics/average_rainfall_deph_storm.tif',6)
mapa4=plot_map(df.map,legenda,titulo = '(d) Average rain deph \n per storm (mm)',shapefile_df)
figure2=grid.arrange(arrangeGrob(mapa1,mapa2,mapa3,mapa4,nrow = 2))
ggsave("D:/Proyectos_GitHub/Bartlet-Lewis_Regionalization/output/img/storm_characteristics.png",figure2,dpi=1200,units = 'cm',width =20 ,height =20 )
1+2
5*9
1
1.2
TRUE
FALSE
True
TRUE
FALSE
1+1
1*2
1/9
3**2
3^2
5**3
"Hola mundo"
Hola mundo
3**2
3**2
9+9
3**2
9+9
3**2
9+9
3**2
9+9
x = 8
x+x
2*x
x**2
x**3
x = 8
x = 9
x
cuadrado = function(x){
return(x**2)
}
cuadrado = function(x){
# Esta funcion sirve para elevar numeros al cuadrado
return(x**2)
}
cuadrado(9)
3**2
cuadrado(8)
cuadrado(7)
Cuadrado(1)
potencia = function(x,n){
return(x**n)
}
potencia = function(x,n){
return(x**n)
}
return(x**n)
potencia(7,3)
potencia(8,5)
Potencia(1,1)
potencia(8,7)
install.packages("plotly")
library(plotly)
library(plotly)
library(plotly)
library(plotly)
library(plumber)
detach("package:plumber", unload = TRUE)
library(raster)
library(plotly)
USPersonalExpenditure <- data.frame("Categorie"=rownames(USPersonalExpenditure), USPersonalExpenditure)
x = 1
x
x <- 2
x
View(USPersonalExpenditure)
USPersonalExpenditure
USPersonalExpenditure[,'Categorie']
c(1,2,3)
c("a","b","c")
USPersonalExpenditure[,c('Categorie','X1940')]
data = USPersonalExpenditure[,c('Categorie', 'X1960')]
data
fig = plotly::plot_ly(data, labels = ~Categorie, values = ~X1960, type = 'pie')
fig = fig %>% layout(title = 'United States Personal Expenditures by Categories in 1960',
xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
fig
# Load the plotly library
library(plotly)
# Create sample data
data <- data.frame(
category = c("A", "B", "C", "D"),
values = c(23, 17, 35, 29)
)
# Create a bar chart
fig <- plot_ly(
data,
x = ~category,
y = ~values,
type = 'bar',
marker = list(color = 'rgba(58, 71, 80, 0.6)', line = list(color = 'rgba(58, 71, 80, 1.0)', width = 1.5))
)
# Add titles
fig <- fig %>%
layout(
title = "Sample Bar Chart",
xaxis = list(title = "Category"),
yaxis = list(title = "Values")
)
# Display the plot
fig
setwd("D:/Proyectos_GitHub/Diseno_experimental/tarea2")
#librerias para series de tiempo
library(lubridate)
library(zoo)
#librerias para graficos
library(plotly)
library(ggplot2)
library(readr)  # Asegúrate de tener esta librería para usar `parse_number`
#aa1 es temperatura del ano 2022
#aa2 es temperatura del ano 2023
aa1<-read.csv('2022_Toribio_04_1-1-22_00-00_1_Year_1719460093_v2.csv', header = F,skip=6)
aa1<-aa1[1:(dim(aa1)[1]-1),]
aa2<-read.csv('2023_Toribio_04_1-1-23_00-00_1_Year_1719460101_v2.csv', header = F,skip=6)
aa2<-aa2[1:(dim(aa2)[1]-1),]
dates1 <- as.POSIXct(aa1$V1, format = "%d/%m/%Y %H:%M")
dates2 <- as.POSIXct(aa2$V1, format = "%d/%m/%Y %H:%M")
# Combinar datos
aa <- rbind(aa1, aa2)
dates <- c(dates1, dates2)
# Crear objeto zoo para la temperatura (V3 se supone que es la columna de temperatura)
datazoo <- zoo(readr::parse_number(aa$V3) / 10, order.by = dates)
# Calcular la media mensual
mes_temp <- aggregate(datazoo, format(index(datazoo), "%Y-%m"), mean)
# Separar las temperaturas de 2022 y 2023
temp_2022 <- mes_temp[1:12]
temp_2023 <- mes_temp[13:24]
plot(datesmonths,mes_temp,xlab="Fecha",ylab="Temperatura",main="Temperatura promedio mensual - Chachapoyas 2022-2023",lwd=4, pch = 19,type="b",cex.lab=1.5, cex.axis=2, cex.main=2.5,col="brown1")
print(t_test_result)
setwd("D:/Proyectos_GitHub/Diseno_experimental/tarea2")
#librerias para series de tiempo
library(lubridate)
library(zoo)
#librerias para graficos
library(plotly)
library(ggplot2)
library(readr)  # Asegúrate de tener esta librería para usar `parse_number`
#aa1 es temperatura del ano 2022
#aa2 es temperatura del ano 2023
aa1<-read.csv('2022_Toribio_04_1-1-22_00-00_1_Year_1719460093_v2.csv', header = F,skip=6)
aa1<-aa1[1:(dim(aa1)[1]-1),]
aa2<-read.csv('2023_Toribio_04_1-1-23_00-00_1_Year_1719460101_v2.csv', header = F,skip=6)
aa2<-aa2[1:(dim(aa2)[1]-1),]
dates1 <- as.POSIXct(aa1$V1, format = "%d/%m/%Y %H:%M")
dates2 <- as.POSIXct(aa2$V1, format = "%d/%m/%Y %H:%M")
# Combinar datos
aa <- rbind(aa1, aa2)
dates <- c(dates1, dates2)
# Crear objeto zoo para la temperatura (V3 se supone que es la columna de temperatura)
datazoo <- zoo(readr::parse_number(aa$V3) / 10, order.by = dates)
# Calcular la media mensual
mes_temp <- aggregate(datazoo, format(index(datazoo), "%Y-%m"), mean)
# Separar las temperaturas de 2022 y 2023
temp_2022 <- mes_temp[1:12]
temp_2023 <- mes_temp[13:24]
plot(datesmonths,mes_temp,xlab="Fecha",ylab="Temperatura",main="Temperatura promedio mensual - Chachapoyas 2022-2023",lwd=4, pch = 19,type="b",cex.lab=1.5, cex.axis=2, cex.main=2.5,col="brown1")
# Realizar el test de t de Student
t_test_result <- t.test(coredata(temp_2022), coredata(temp_2023), var.equal = TRUE)
print(t_test_result)
#plot(datesmonths,mes_temp,xlab="Fecha",ylab="Temperatura",main="Temperatura promedio mensual - Chachapoyas 2022-2023",lwd=4, pch = 19,type="b",cex.lab=1.5, cex.axis=2, cex.main=2.5,col="brown1")
# Realizar el test de t de Student
t_test_result <- t.test(coredata(temp_2022), coredata(temp_2023), var.equal = TRUE)
print(t_test_result)
#Precipitacion
datazoo <- zoo(readr::parse_number(aa$V18)/10, order.by = dates)
yyddmm=paste0(sprintf("%02d", year(dates)),sprintf("%02d", month(dates)),sprintf("%02d", day(dates)))
yyddmm2=c(rep("211231",28),yyddmm[1:(length(yyddmm)-28)])
df<-data.frame(data=datazoo,dates=dates,yyddmm=yyddmm2)
day_pp<-aggregate(datazoo ~ yyddmm, data=df, FUN=sum)
day_pp<-day_pp[2:dim(day_pp)[1],]
str(day_pp$datazoo)
#---------------- Estimación de acumulados diarios ----------------------------
datesdays<-seq(as.Date('2022-01-01'),as.Date('2023-12-31'),by='days')
datazoo_day <- zoo(day_pp$datazoo, order.by = datesdays)
plot(datazoo_day,xlab="Fecha",ylab="Precipitación",main="Precipitación diaria - Chachapoyas 2022-2023",
cex.lab=1.7, cex.axis=2, cex.main=2.5,col="olivedrab3",lwd=2.5)
grid()
# Corregir la función aggregate para sumar la precipitación mensual
monthly_sum <- aggregate(day_pp$datazoo, by = list(format(index(datazoo_day), "%Y-%m")), FUN = sum)
names(monthly_sum) = c('Fecha','pp')
# Separar precipitacion de 2022 y 2023
pcp_2022 <- monthly_sum[1:12, ]
pcp_2023 <- monthly_sum[13:24, ]
# Corregir la conversión de las fechas a Date
monthly_sum$Fecha <- as.Date(paste0(monthly_sum$Fecha, "-01"))
# Graficar la precipitación mensual
plot(x = monthly_sum$Fecha, y = monthly_sum$pp,
xlab = "Fecha", ylab = "Precipitación",
main = "Precipitación mensual - Chachapoyas 2022-2023",
cex.lab = 1.7, cex.axis = 2, cex.main = 2.5,
col = "olivedrab3", lwd = 2.5, type = "b") # type = "b" para líneas y puntos
grid()
# Realizar el test de t de Student
pp_test_result <- t.test(coredata(pcp_2022$pp), coredata(pcp_2023$pp), var.equal = TRUE)
print(pp_test_result)
plot(datazoo,xlab="Fecha",ylab="Temperatura",main="Temperatura promedio mensual - Chachapoyas 2022-2023",lwd=4, pch = 19,type="b",cex.lab=1.5, cex.axis=2, cex.main=2.5,col="brown1")
plot(mes_temp,xlab="Fecha",ylab="Temperatura",main="Temperatura promedio mensual - Chachapoyas 2022-2023",lwd=4, pch = 19,type="b",cex.lab=1.5, cex.axis=2, cex.main=2.5,col="brown1")
plot(mes_temp,xlab="Fecha",ylab="Temperatura",main="Temperatura promedio mensual - Chachapoyas 2022-2023",lwd=4, pch = 19,type="b",cex.lab=1.5, cex.axis=2, cex.main=2.5,col="brown1")
plot(mes_temp,xlab="Fecha",ylab="Temperatura",main="Temperatura promedio mensual - Chachapoyas 2022-2023",lwd=4, pch = 19,type="b",cex.lab=1.5, cex.axis=2, cex.main=2.5,col="brown1")
mes_temp
plot(mes_temp, xlab = "Fecha", ylab = "Temperatura",
main = "Temperatura promedio mensual - Chachapoyas 2022-2023",
lwd = 4, pch = 19, type = "b", cex.lab = 1.5, cex.axis = 2,
cex.main = 2.5, col = "brown1")
plot(dates,mes_temp,xlab="Fecha",ylab="Temperatura",main="Temperatura promedio mensual - Chachapoyas 2022-2023",lwd=4, pch = 19,type="b",cex.lab=1.5, cex.axis=2, cex.main=2.5,col="brown1")
dates
mes_temp
index(mes_temp)
plot(index(mes_temp),mes_temp,xlab="Fecha",ylab="Temperatura",main="Temperatura promedio mensual - Chachapoyas 2022-2023",lwd=4, pch = 19,type="b",cex.lab=1.5, cex.axis=2, cex.main=2.5,col="brown1")
plot(index(mes_temp,coredata(mes_temp),xlab="Fecha",ylab="Temperatura",main="Temperatura promedio mensual - Chachapoyas 2022-2023",lwd=4, pch = 19,type="b",cex.lab=1.5, cex.axis=2, cex.main=2.5,col="brown1")
plot(index(mes_temp),coredata(mes_temp),xlab="Fecha",ylab="Temperatura",main="Temperatura promedio mensual - Chachapoyas 2022-2023",lwd=4, pch = 19,type="b",cex.lab=1.5, cex.axis=2, cex.main=2.5,col="brown1")
plot(index(mes_temp),coredata(mes_temp),xlab="Fecha",ylab="Temperatura",main="Temperatura promedio mensual - Chachapoyas 2022-2023",lwd=4, pch = 19,type="b",cex.lab=1.5, cex.axis=2, cex.main=2.5,col="brown1")
pcp_2022
mes_temp
setwd("D:/Proyectos_GitHub/Diseno_experimental/tarea2")
#librerias para series de tiempo
library(lubridate)
library(zoo)
#librerias para graficos
library(plotly)
library(ggplot2)
library(readr)  # Asegúrate de tener esta librería para usar `parse_number`
#aa1 es temperatura del ano 2022
#aa2 es temperatura del ano 2023
aa1<-read.csv('2022_Toribio_04_1-1-22_00-00_1_Year_1719460093_v2.csv', header = F,skip=6)
aa1<-aa1[1:(dim(aa1)[1]-1),]
aa2<-read.csv('2023_Toribio_04_1-1-23_00-00_1_Year_1719460101_v2.csv', header = F,skip=6)
aa2<-aa2[1:(dim(aa2)[1]-1),]
dates1 <- as.POSIXct(aa1$V1, format = "%d/%m/%Y %H:%M")
dates2 <- as.POSIXct(aa2$V1, format = "%d/%m/%Y %H:%M")
# Combinar datos
aa <- rbind(aa1, aa2)
dates <- c(dates1, dates2)
# Crear objeto zoo para la temperatura (V3 se supone que es la columna de temperatura)
datazoo <- zoo(readr::parse_number(aa$V3) / 10, order.by = dates)
# Calcular la media mensual
mes_temp <- aggregate(datazoo, format(index(datazoo), "%Y-%m"), mean)
# Separar las temperaturas de 2022 y 2023
mes_temp
mes_temp$
mes_temp
setwd("D:/Proyectos_GitHub/Diseno_experimental/clase")
datos = read.csv("DCA.csv")
datos
datos = read.csv("DCA.csv",sep = ';')
datos
my_data = read.csv("DCA.csv",sep = ';')
anova(lm(PRODUCCION ~ METODOS, data = my_data))
res.aov <- aov(PRODUCCION ~ METODOS, data = my_data)
# Summary of the analysis
summary(res.aov)
res.aov
res.aov$residuals
View(res.aov)
TukeyHSD(res.aov)
TukeyHSD(res.aov)
TukeyHSD(res.aov)
# Extract the residuals
aov_residuals <- residuals(object = res.aov )
# Run Shapiro-Wilk test
shapiro.test(x = aov_residuals )
plot(res.aov, 2)
# 2. Homogeneity of variances
result = bartlett.test(PRODUCCION ~ METODOS, data = my_data)
# print the result
print(result)
